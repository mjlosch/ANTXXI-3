#!/bin/bash
#SBATCH -J eifex_opt
##SBATCH -p mpp
#SBATCH --account=clidyn.clidyn
#SBATCH -n 4
#SBATCH --cpus-per-task=2
#SBATCH -t 00:30:00
#SBATCH -o output.txt

# list of hosts that you are running on
hostlist=$(scontrol show hostnames | tr '\n' ',' | rev | cut -c 2- | rev)
echo "hosts: $hostlist"
umask 022

# load modules (to be sure they are really loaded)
module purge # to remove anything that may conflict with ifort
module load intel-oneapi-compilers
# module load intel-oneapi-mkl # not sure if this is necessary
module load intel-oneapi-mpi
module load netcdf-fortran/4.5.4-oneapi2022.1.0

ulimit -s 1048576

#export I_MPI_PIN=1 # binds mpi task to given cores
#export I_MPI_FABRICS=shm:tmi # very important if you want to run on more than one node!!!
#export MALLOC_MMAP_MAX_=0
#export OMP_NUM_THREADS=${nthreads}
export OMP_NUM_THREADS=1
#export OMP_PROC_BIND=close

cd ${SLURM_SUBMIT_DIR}

# show number of tasks, cpus,...
echo "SLURM_NTASKS        : $SLURM_NTASKS"
echo "SLURM_TASKS_PER_NODE: $SLURM_TASKS_PER_NODE"
echo "SLURM_CPUS_PER_TASK : $SLURM_CPUS_PER_TASK"
echo "OMP_NUM_THREADS     : $OMP_NUM_THREADS"
echo "OMP_PROC_BIND       : $OMP_PROC_BIND"

optdir="../opt01"
myiter=151
cat > data.optim <<EOF #
# ********************************
# Off-line optimization parameters
# ********************************
&OPTIM
 optimcycle=$myiter,
 numiter=200,
 nfunc=10,
 dfminFrac = 0.1,
 iprint=10,
 nupdate=8,
/

&M1QN3
/
EOF

ln -s ../input/* . > /dev/null 2>&1
exe=../build/mitgcmuv

# format iteration count
it=`echo $myiter | awk '{printf "%04i",$1}'`
echo "iteration ${myiter}"

ln -s ${optdir}/ecco_ctrl_MIT_CE_000.opt${it}
ln -s ${optdir}/data.ctrl .
ln -s ${optdir}/data.err .

echo "srun --cpu_bind=cores $exe"
srun --cpu_bind=cores $exe

\cp -rf STDOUT.0000 stdout.$it

#echo "cleaning up"
#find . -type l -exec rm {} \;
#\rm -rf *.log
